{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The DiTau Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found backend type matching \"xaod\". Matching by type is depreciated. Please switch to using the \"name\" keyword in your servicex.yaml file.\n",
      "Found backend type matching \"xaod\". Matching by type is depreciated. Please switch to using the \"name\" keyword in your servicex.yaml file.\n",
      "Found backend type matching \"xaod\". Matching by type is depreciated. Please switch to using the \"name\" keyword in your servicex.yaml file.\n",
      "Found backend type matching \"xaod\". Matching by type is depreciated. Please switch to using the \"name\" keyword in your servicex.yaml file.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from config import ds_ztautau as ds\n",
    "import awkward as ak\n",
    "from helpers import match_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, we fetch `DiTauJets` from..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Docker image and tag: atlas/analysisbase:21.2.197\n",
      "Docker Output: \n",
      "  Configured GCC from: /opt/lcg/gcc/8.3.0-cebb0/x86_64-centos7/bin/gcc\n",
      "  Configured AnalysisBase from: /usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt\n",
      "  -- The C compiler identification is GNU 8.3.0\n",
      "  -- The CXX compiler identification is GNU 8.3.0\n",
      "  -- Detecting C compiler ABI info\n",
      "  -- Detecting C compiler ABI info - done\n",
      "  -- Check for working C compiler: /opt/lcg/gcc/8.3.0-cebb0/x86_64-centos7/bin/gcc - skipped\n",
      "  -- Detecting C compile features\n",
      "  -- Detecting C compile features - done\n",
      "  -- Detecting CXX compiler ABI info\n",
      "  -- Detecting CXX compiler ABI info - done\n",
      "  -- Check for working CXX compiler: /opt/lcg/gcc/8.3.0-cebb0/x86_64-centos7/bin/g++ - skipped\n",
      "  -- Detecting CXX compile features\n",
      "  -- Detecting CXX compile features - done\n",
      "  -- Found AnalysisBase: /usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt (version: 21.2.197)\n",
      "  -- Found AnalysisBaseExternals: /usr/AnalysisBaseExternals/21.2.197/InstallArea/x86_64-centos7-gcc8-opt (version: 21.2.197)\n",
      "  -- Setting ATLAS specific build flags\n",
      "  -- checker_gccplugins library not found\n",
      "  -- Package(s) in AnalysisBaseExternals: 22\n",
      "  -- Using the LCG modules without setting up a release\n",
      "  -- Package(s) in AnalysisBase: 196\n",
      "  -- Looking for pthread.h\n",
      "  -- Looking for pthread.h - found\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n",
      "  -- Check if compiler accepts -pthread\n",
      "  -- Check if compiler accepts -pthread - yes\n",
      "  -- Found Threads: TRUE  \n",
      "  -- Configuring ATLAS project with name \"UserAnalysis\" and version \"1.0.0\"\n",
      "  -- Using build type: RelWithDebInfo\n",
      "  -- Using platform name: x86_64-centos7-gcc8-opt\n",
      "  -- Cleaning stale files from build area\n",
      "  -- Unit tests will be built by default\n",
      "  -- Found 1 package(s)\n",
      "  -- Considering package 1 / 1\n",
      "  -- No package filtering rules read\n",
      "  -- Configuring the build of package: analysis\n",
      "  -- Number of packages configured: 1\n",
      "  -- Time for package configuration: 0 seconds\n",
      "  -- Including the packages from project AnalysisBase - 21.2.197...\n",
      "  -- Including the packages from project AnalysisBaseExternals - 21.2.197...\n",
      "  -- Generated file: /workdir/rel/build/x86_64-centos7-gcc8-opt/packages.txt\n",
      "  -- Generated file: /workdir/rel/build/x86_64-centos7-gcc8-opt/compilers.txt\n",
      "  -- Generated file: /workdir/rel/build/x86_64-centos7-gcc8-opt/ReleaseData\n",
      "  -- Generating external environment configuration\n",
      "  -- Writing runtime environment to file: /workdir/rel/build/x86_64-centos7-gcc8-opt/env_setup.sh\n",
      "  -- Configuring done\n",
      "  -- Generating done\n",
      "  -- Build files have been written to: /workdir/rel/build\n",
      "  Scanning dependencies of target queryDictDictGen\n",
      "  [ 11%] Generating queryDictReflexDict.cxx\n",
      "  [ 11%] Built target queryDictDictGen\n",
      "  [ 22%] Built UserAnalysisRootMapMerge\n",
      "  [ 22%] Built target UserAnalysisRootMapMerge\n",
      "  [ 22%] Built target Package_analysis_tests\n",
      "  [ 22%] Built target atlas_tests\n",
      "  [ 33%] Generating ../x86_64-centos7-gcc8-opt/bin/ATestRun_eljob.py\n",
      "  [ 33%] Built target analysisScriptsInstall\n",
      "  [ 44%] Building CXX object analysis/CMakeFiles/analysisLib.dir/Root/query.cxx.o\n",
      "  [ 55%] Linking CXX shared library ../x86_64-centos7-gcc8-opt/lib/libanalysisLib.so\n",
      "  Detaching debug info of libanalysisLib.so into libanalysisLib.so.dbg\n",
      "  [ 55%] Built target analysisLib\n",
      "  [ 66%] Generating ../x86_64-centos7-gcc8-opt/include/analysis\n",
      "  [ 66%] Built target analysisHeaderInstall\n",
      "  [ 66%] Built target analysisJobOptInstall\n",
      "  [ 77%] Building CXX object analysis/CMakeFiles/queryDict.dir/CMakeFiles/queryDictReflexDict.cxx.o\n",
      "  [ 88%] Linking CXX shared library ../x86_64-centos7-gcc8-opt/lib/libqueryDict.so\n",
      "  Detaching debug info of libqueryDict.so into libqueryDict.so.dbg\n",
      "  [ 88%] Built target queryDict\n",
      "  [100%] Built package analysis\n",
      "  analysis: Package build succeeded\n",
      "  [100%] Built target Package_analysis\n",
      "  xAOD::Init                INFO    Environment initialised for data access\n",
      "  SampleHandler with 1 files\n",
      "  Sample:name=ANALYSIS,tags=()\n",
      "  file:///data/DAOD_PHYS.23295108._000430.pool.root.1\n",
      "  \n",
      "  \n",
      "  /*** AlgSequence/DiTauAnalysisSequence_Tight ***********************************\n",
      "  | /*** PythonConfig AnaAlgorithm/CP::DiTauSmearingAlg/DiTauSmearingAlg_Tight *****\n",
      "  | |- smearingTool:  \n",
      "  | | /*** Private Tool TauAnalysisTools::DiTauSmearingTool/smearingTool *************\n",
      "  | | \\--- (End of Private Tool TauAnalysisTools::DiTauSmearingTool/smearingTool) ----\n",
      "  | |- taus: 'DiTauJets'\n",
      "  | |- tausOut: 'DiTauJets_Tight_%SYS%'\n",
      "  | \\--- (End of PythonConfig AnaAlgorithm/CP::DiTauSmearingAlg/DiTauSmearingAlg_Tight) \n",
      "  | /*** PythonConfig AnaAlgorithm/CP::KinematicHistAlg/DiTauKinematicDumperAlg_Tight \n",
      "  | |- histPattern: 'tau_%VAR%_%SYS%'\n",
      "  | |- input: 'DiTauJets_Tight_%SYS%'\n",
      "  | \\--- (End of PythonConfig AnaAlgorithm/CP::KinematicHistAlg/DiTauKinematicDumperAlg_Tight) \n",
      "  | /*** PythonConfig AnaAlgorithm/CP::DiTauEfficiencyCorrectionsAlg/DiTauEfficiencyCorrectionsAlg_Tight \n",
      "  | |- efficiencyCorrectionsTool:  \n",
      "  | | /*** Private Tool TauAnalysisTools::DiTauEfficiencyCorrectionsTool/efficiencyCorrectionsTool \n",
      "  | | |- IDLevel: 4\n",
      "  | | \\--- (End of Private Tool TauAnalysisTools::DiTauEfficiencyCorrectionsTool/efficiencyCorrectionsTool) \n",
      "  | |- scaleFactorDecoration: 'tau_effSF_Tight'\n",
      "  | |- taus: 'DiTauJets_Tight_%SYS%'\n",
      "  | \\--- (End of PythonConfig AnaAlgorithm/CP::DiTauEfficiencyCorrectionsAlg/DiTauEfficiencyCorrectionsAlg_Tight) \n",
      "  | /*** PythonConfig AnaAlgorithm/CP::DiTauTruthMatchingAlg/DiTauTruthMatchingAlg_Tight \n",
      "  | |- matchingTool:  \n",
      "  | | /*** Private Tool TauAnalysisTools::DiTauTruthMatchingTool/matchingTool ********\n",
      "  | | |- WriteTruthTaus: 1\n",
      "  | | \\--- (End of Private Tool TauAnalysisTools::DiTauTruthMatchingTool/matchingTool) \n",
      "  | |- taus: 'DiTauJets_Tight_%SYS%'\n",
      "  | \\--- (End of PythonConfig AnaAlgorithm/CP::DiTauTruthMatchingAlg/DiTauTruthMatchingAlg_Tight) \n",
      "  \\--- (End of AlgSequence/DiTauAnalysisSequence_Tight) --------------------------\n",
      "  <ROOT.EL::Job object at 0x7d43c40>\n",
      "  Package.EventLoop        INFO    created submission directory /workdir/rel/build/bogus\n",
      "  Package.EventLoop        INFO    submitting job in /workdir/rel/build/bogus\n",
      "  Package.EventLoop        INFO    Running sample: ANALYSIS\n",
      "  Package.EventLoop        INFO    xAODInput = 1\n",
      "  Package.EventLoop        INFO    calling firstInitialize on all modules\n",
      "  Package.EventLoop        INFO    calling preFileInitialize on all modules\n",
      "  xAOD::LoadDictionaries    INFO    xAOD EDM dictionaries loaded\n",
      "  Package.EventLoop        INFO    Opening file file:///data/DAOD_PHYS.23295108._000430.pool.root.1\n",
      "  PileupReweightingAlg.p...WARNING No config files provided, but 4 lumicalc file provided. Assuming a period config of MC16 \n",
      "  CP::TPileupReweighting... INFO    Using MC16 Period configuration\n",
      "  CP::TPileupReweighting... INFO    Using MC16 Period configuration\n",
      "  CP::TPileupReweighting... INFO    Using MC16 Period configuration\n",
      "[TFile::Cp] Total 4.45 MB\t|====================| 100.00 % [2.8 MB/s]0.0 MB/s]\n",
      "  PathResolver             INFO    Successfully downloaded http://cern.ch/atlas-groupdata/GoodRunsLists/data15_13TeV/20170619/PHYS_StandardGRL_All_Good_25ns_276262-284484_OflLumi-13TeV-008.root\n",
      "  CP::TPileupReweighting... INFO    Adding LumiMetaData (scale factor=0.970874)...\n",
      "  CP::TPileupReweighting... INFO    Adding LumiMetaData (scale factor=1.010101)...\n",
      "  CP::TPileupReweighting... INFO    Adding LumiMetaData (scale factor=0.934579)...\n",
      "[TFile::Cp] Total 17.57 MB\t|====================| 100.00 % [2.5 MB/s]0.0 MB/s]\n",
      "  PathResolver             INFO    Successfully downloaded http://cern.ch/atlas-groupdata/GoodRunsLists/data16_13TeV/20180129/PHYS_StandardGRL_All_Good_25ns_297730-311481_OflLumi-13TeV-009.root\n",
      "  CP::TPileupReweighting... INFO    Adding LumiMetaData (scale factor=0.970874)...\n",
      "  CP::TPileupReweighting... INFO    Adding LumiMetaData (scale factor=1.010101)...\n",
      "  CP::TPileupReweighting... INFO    Adding LumiMetaData (scale factor=0.934579)...\n",
      "[TFile::Cp] Total 16.57 MB\t|====================| 100.00 % [2.1 MB/s]0.0 MB/s]\n",
      "  PathResolver             INFO    Successfully downloaded http://cern.ch/atlas-groupdata/GoodRunsLists/data17_13TeV/20180619/physics_25ns_Triggerno17e33prim.lumicalc.OflLumi-13TeV-010.root\n",
      "  CP::TPileupReweighting... INFO    Adding LumiMetaData (scale factor=0.970874)...\n",
      "  CP::TPileupReweighting... INFO    Adding LumiMetaData (scale factor=1.010101)...\n",
      "  CP::TPileupReweighting... INFO    Adding LumiMetaData (scale factor=0.934579)...\n",
      "[TFile::Cp] Total 17.49 MB\t|====================| 100.00 % [2.2 MB/s]0.0 MB/s]\n",
      "  PathResolver             INFO    Successfully downloaded http://cern.ch/atlas-groupdata/GoodRunsLists/data18_13TeV/20190708/ilumicalc_histograms_None_348885-364292_OflLumi-13TeV-010.root\n",
      "  CP::TPileupReweighting... INFO    Adding LumiMetaData (scale factor=0.970874)...\n",
      "  CP::TPileupReweighting... INFO    Adding LumiMetaData (scale factor=1.010101)...\n",
      "  CP::TPileupReweighting... INFO    Adding LumiMetaData (scale factor=0.934579)...\n",
      "  DefaultWeightTool        INFO    AsgTool DefaultWeightTool @ 0x111ed2f0\n",
      "  (stderr) In file included from libTauAnalysisAlgorithmsDict dictionary payload:48:\n",
      "  (stderr) In file included from /usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/TauAnalysisAlgorithms/DiTauEfficiencyCorrectionsAlg.h:12:\n",
      "  (stderr) In file included from /usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/TauAnalysisTools/IDiTauEfficiencyCorrectionsTool.h:23:\n",
      "  (stderr) In file included from /usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/xAODTau/DiTauJet.h:12:\n",
      "  (stderr) /usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/xAODTau/versions/DiTauJet_v1.h:168:1: error: explicit specialization of 'DataVectorBase<xAOD::DiTauJet_v1>' after instantiation\n",
      "  (stderr) DATAVECTOR_BASE( xAOD::DiTauJet_v1, xAOD::IParticle );\n",
      "  (stderr) ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  (stderr) /usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/AthContainers/DataVector.h:612:43: note: expanded from macro 'DATAVECTOR_BASE'\n",
      "  (stderr) #define DATAVECTOR_BASE(T, BASE)          \\\n",
      "  (stderr)                                           ^\n",
      "  (stderr) /usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/AthContainers/DataVector.h:622:20: note: expanded from macro '\\\n",
      "  (stderr) DATAVECTOR_BASE_FWD'\n",
      "  (stderr) template <> struct DataVectorBase<T>      \\\n",
      "  (stderr)                    ^~~~~~~~~~~~~~~~~\n",
      "  (stderr) /usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/AthContainers/DataVector.h:718:42: note: implicit instantiation first required here\n",
      "  (stderr) template <class T, class BASE = typename DataVectorBase<T>::Base>\n",
      "  (stderr)                                          ^\n",
      "  TInterpreter::AutoParse   ERROR   Error parsing payload code for class CP::DiTauSmearingAlg with content:\n",
      "  \n",
      "  #line 1 \"libTauAnalysisAlgorithmsDict dictionary payload\"\n",
      "  \n",
      "  #ifndef HAVE_PRETTY_FUNCTION\n",
      "    #define HAVE_PRETTY_FUNCTION 1\n",
      "  #endif\n",
      "  #ifndef HAVE_64_BITS\n",
      "    #define HAVE_64_BITS 1\n",
      "  #endif\n",
      "  #ifndef __IDENTIFIER_64BIT__\n",
      "    #define __IDENTIFIER_64BIT__ 1\n",
      "  #endif\n",
      "  #ifndef ATLAS\n",
      "    #define ATLAS 1\n",
      "  #endif\n",
      "  #ifndef ROOTCORE\n",
      "    #define ROOTCORE 1\n",
      "  #endif\n",
      "  #ifndef XAOD_STANDALONE\n",
      "    #define XAOD_STANDALONE 1\n",
      "  #endif\n",
      "  #ifndef XAOD_ANALYSIS\n",
      "    #define XAOD_ANALYSIS 1\n",
      "  #endif\n",
      "  #ifndef ROOTCORE_RELEASE_SERIES\n",
      "    #define ROOTCORE_RELEASE_SERIES 25\n",
      "  #endif\n",
      "  #ifndef PACKAGE_VERSION\n",
      "    #define PACKAGE_VERSION \"TauAnalysisAlgorithms-00-00-00\"\n",
      "  #endif\n",
      "  #ifndef PACKAGE_VERSION_UQ\n",
      "    #define PACKAGE_VERSION_UQ TauAnalysisAlgorithms-00-00-00\n",
      "  #endif\n",
      "  #ifndef EIGEN_DONT_VECTORIZE\n",
      "    #define EIGEN_DONT_VECTORIZE 1\n",
      "  #endif\n",
      "  \n",
      "  #define _BACKWARD_BACKWARD_WARNING_H\n",
      "  // Inline headers\n",
      "  /*\n",
      "    Copyright (C) 2002-2018 CERN for the benefit of the ATLAS collaboration\n",
      "  */\n",
      "  \n",
      "  /// @author Nils Krumnack\n",
      "  \n",
      "  \n",
      "  #ifndef TAU_ANALYSIS_ALGORITHMS__TAU_ANALYSIS_ALGORITHMS_DICT_H\n",
      "  #define TAU_ANALYSIS_ALGORITHMS__TAU_ANALYSIS_ALGORITHMS_DICT_H\n",
      "  \n",
      "  #include <TauAnalysisAlgorithms/DiTauEfficiencyCorrectionsAlg.h>\n",
      "  #include <TauAnalysisAlgorithms/DiTauSmearingAlg.h>\n",
      "  #include <TauAnalysisAlgorithms/DiTauTruthMatchingAlg.h>\n",
      "  #include <TauAnalysisAlgorithms/TauEfficiencyCorrectionsAlg.h>\n",
      "  #include <TauAnalysisAlgorithms/TauSmearingAlg.h>\n",
      "  #include <TauAnalysisAlgorithms/TauTruthMatchingAlg.h>\n",
      "  \n",
      "  #endif\n",
      "  \n",
      "  #undef  _BACKWARD_BACKWARD_WARNING_H\n",
      "  \n",
      "  (stderr) input_line_367:2:39: error: allocation of incomplete type 'CP::DiTauSmearingAlg'\n",
      "  (stderr)  dynamic_cast<asg::AsgComponent*>(new CP::DiTauSmearingAlg (\"DiTauSmearingAlg_Tight\", nullptr))\n",
      "  (stderr)                                       ^~~~~~~~~~~~~~~~~~~~\n",
      "  (stderr) libTauAnalysisAlgorithmsDict dictionary forward declarations' payload:6:106: note: forward declaration of 'CP::DiTauSmearingAlg'\n",
      "  (stderr) namespace CP{class __attribute__((annotate(\"$clingAutoload$TauAnalysisAlgorithms/DiTauSmearingAlg.h\")))  DiTauSmearingAlg;}\n",
      "  (stderr)                                                                                                          ^\n",
      "  Package.AsgTools.Compo...ERROR   /build/atnight/localbuilds/nightlies/AnalysisBase/21.2/athena/Control/AthToolSupport/AsgTools/Root/AsgComponentConfig.cxx:277 (StatusCode asg::{anonymous}::createComponent(std::unique_ptr<asg::AsgComponent>&, const string&, const string&, const string&)): failed to create component of type CP::DiTauSmearingAlg\n",
      "  Package.AsgTools.Compo...ERROR   /build/atnight/localbuilds/nightlies/AnalysisBase/21.2/athena/Control/AthToolSupport/AsgTools/Root/AsgComponentConfig.cxx:278 (StatusCode asg::{anonymous}::createComponent(std::unique_ptr<asg::AsgComponent>&, const string&, const string&, const string&)): make sure you created a dictionary for your component\n",
      "  Package.EventLoopComp_...ERROR   /build/atnight/localbuilds/nightlies/AnalysisBase/21.2/athena/PhysicsAnalysis/D3PDTools/AnaAlgorithm/Root/AnaAlgorithmConfig.cxx:89 (StatusCode EL::AnaAlgorithmConfig::makeAlgorithm(std::unique_ptr<EL::AnaAlgorithm>&, const EL::AlgorithmWorkerData&) const): Failed to call \"makeComponentExpert (algorithm, \"new %1% (\\\"%2%\\\", nullptr)\", true, \"\")\"\n",
      "  Package.EventLoopComp_...ERROR   /build/atnight/localbuilds/nightlies/AnalysisBase/21.2/athena/PhysicsAnalysis/D3PDTools/AnaAlgorithm/Root/AnaAlgorithmWrapper.cxx:73 (virtual StatusCode EL::AnaAlgorithmWrapper::initialize(const EL::AlgorithmWorkerData&)): failed to create AnaAlgorithm: DiTauSmearingAlg_Tight\n",
      "  Package.EventLoop        ERROR   /build/atnight/localbuilds/nightlies/AnalysisBase/21.2/athena/PhysicsAnalysis/D3PDTools/EventLoop/Root/AlgorithmStateModule.cxx:45 (StatusCode EL::Detail::{anonymous}::forAllAlgorithms(EL::Detail::ModuleData&, const char*, F&&) [with F = EL::Detail::AlgorithmStateModule::onInitialize(EL::Detail::ModuleData&)::<lambda(EL::Detail::AlgorithmData&)>]): executing initialize on algorithm DiTauSmearingAlg_Tight\n",
      "  Package.EventLoop        ERROR   /build/atnight/localbuilds/nightlies/AnalysisBase/21.2/athena/PhysicsAnalysis/D3PDTools/EventLoop/Root/Worker.cxx:495 (StatusCode EL::Worker::processEvents(EL::EventRange&)): Failed to call \"module->onInitialize (*this)\"\n",
      "  Package.EventLoop        ERROR   /build/atnight/localbuilds/nightlies/AnalysisBase/21.2/athena/PhysicsAnalysis/D3PDTools/EventLoop/Root/Worker.cxx:769 (StatusCode EL::Worker::directExecute(const SH::SamplePtr&, const EL::Job&, const string&, const SH::MetaObject&)): Failed to call \"processEvents (eventRange)\"\n",
      "  Package.EventLoop        ERROR   /build/atnight/localbuilds/nightlies/AnalysisBase/21.2/athena/PhysicsAnalysis/D3PDTools/EventLoop/Root/DirectDriver.cxx:81 (virtual StatusCode EL::DirectDriver::doManagerStep(EL::Detail::ManagerData&) const): Failed to call \"worker.directExecute (*sample, *data.job, data.submitDir, data.options)\"\n",
      "  Package.EventLoop        ERROR   /build/atnight/localbuilds/nightlies/AnalysisBase/21.2/athena/PhysicsAnalysis/D3PDTools/EventLoop/Root/ManagerData.cxx:67 (StatusCode EL::Detail::ManagerData::run()): while performing manager step 14\n",
      "  Package.EventLoop        ERROR   /build/atnight/localbuilds/nightlies/AnalysisBase/21.2/athena/PhysicsAnalysis/D3PDTools/EventLoop/Root/ManagerData.cxx:68 (StatusCode EL::Detail::ManagerData::run()): on submission directory /workdir/rel/build/bogus\n",
      "  (stderr) Traceback (most recent call last):\n",
      "  (stderr)   File \"../source/analysis/share/ATestRun_eljob.py\", line 91, in <module>\n",
      "  (stderr)     driver.submit(job, options.submission_dir)\n",
      "  (stderr) Exception: string EL::Driver::submit(const EL::Job& job, const string& location) =>\n",
      "  (stderr)     failed to submit job (C++ exception of type runtime_error)\n",
      "  xAOD::TFileAccessTracer   INFO    Sending file access statistics to http://rucio-lb-prod.cern.ch:18762/traces/\n",
      "  \n",
      "ATestRun_eljob.py:\n",
      "  #\n",
      "  # Read the submission directory as a command line argument. You can\n",
      "  # extend the list of arguments with your private ones later on.\n",
      "  # Set up (Py)ROOT.\n",
      "  import ROOT  # type: ignore\n",
      "  import optparse\n",
      "  from AnaAlgorithm.DualUseConfig import createAlgorithm  # type: ignore\n",
      "  \n",
      "  parser = optparse.OptionParser()\n",
      "  \n",
      "  ROOT.xAOD.Init().ignore()\n",
      "  parser.add_option('-s', '--submission-dir', dest='submission_dir',\n",
      "                    action='store', type='string', default='submitDir',\n",
      "                    help='Submission directory for EventLoop')\n",
      "  (options, args) = parser.parse_args()\n",
      "  \n",
      "  \n",
      "  # The sample handler is going to load the files form filelist.txt,\n",
      "  # in this context, it is an embarrassingly easy use of that object.\n",
      "  sh = ROOT.SH.SampleHandler()\n",
      "  sh.setMetaString('nc_tree', 'CollectionTree')\n",
      "  ROOT.SH.readFileList(sh, \"ANALYSIS\", \"filelist.txt\")\n",
      "  sh.printContent()\n",
      "  \n",
      "  # Create an EventLoop job.\n",
      "  job = ROOT.EL.Job()\n",
      "  job.sampleHandler(sh)\n",
      "  \n",
      "  \n",
      "  # pulled from:https://gitlab.cern.ch/atlas/athena/-/blob/21.2/PhysicsAnalysis/Algorithms/JetAnalysisAlgorithms/python/JetAnalysisAlgorithmsTest.py \n",
      "  \n",
      "  # Set up the systematics loader/handler service:\n",
      "  \n",
      "  from AnaAlgorithm.DualUseConfig import createService\n",
      "  \n",
      "  from AnaAlgorithm.AlgSequence import AlgSequence\n",
      "  \n",
      "  calibrationAlgSeq = AlgSequence()\n",
      "  \n",
      "  sysService = createService( 'CP::SystematicsSvc', 'SystematicsSvc', sequence = calibrationAlgSeq )\n",
      "  \n",
      "  sysService.systematicsList = ['NOSYS']\n",
      "  \n",
      "  # Add sequence to job\n",
      "  \n",
      "  from AsgAnalysisAlgorithms.PileupAnalysisSequence import makePileupAnalysisSequence\n",
      "  \n",
      "  from AsgAnalysisAlgorithms.AsgAnalysisAlgorithmsTest import pileupConfigFiles\n",
      "  \n",
      "  prwfiles, lumicalcfiles = pileupConfigFiles('mc')\n",
      "  \n",
      "  # Can't use pwrfiles, lumicalcfiles b.c. they are on cvms and docker does not have those.\n",
      "  \n",
      "  # pileupSequence = makePileupAnalysisSequence( 'mc', userPileupConfigs=prwfiles, userLumicalcFiles=lumicalcfiles)\n",
      "  \n",
      "  pileupSequence = makePileupAnalysisSequence( 'mc' )\n",
      "  \n",
      "  pileupSequence.configure( inputName = {}, outputName = {} )\n",
      "  \n",
      "  # print( pileupSequence ) # For debugging\n",
      "  \n",
      "  calibrationAlgSeq += pileupSequence\n",
      "  \n",
      "  from TauAnalysisAlgorithms.DiTauAnalysisSequence import makeDiTauAnalysisSequence\n",
      "  \n",
      "  diTauSequence = makeDiTauAnalysisSequence( 'mc', 'Tight', postfix = 'Tight')\n",
      "  \n",
      "  diTauSequence.configure( inputName = 'DiTauJets',\n",
      "  \n",
      "                         outputName = 'DiTauJets_Tight_%SYS%' )\n",
      "  \n",
      "  calibrationAlgSeq += diTauSequence\n",
      "  \n",
      "  print( diTauSequence ) # For debugging\n",
      "  \n",
      "  calibrationAlgSeq.addSelfToJob( job )\n",
      "  \n",
      "  print(job) # for debugging\n",
      "  \n",
      "  \n",
      "  # Create the algorithm's configuration.\n",
      "  alg = createAlgorithm('query', 'AnalysisAlg')\n",
      "  # later on we'll add some configuration options for our algorithm that go here\n",
      "  \n",
      "  # Add our algorithm to the job\n",
      "  job.algsAdd(alg)\n",
      "  job.outputAdd(ROOT.EL.OutputStream('ANALYSIS'))\n",
      "  \n",
      "  # Run the job using the direct driver.\n",
      "  driver = ROOT.EL.DirectDriver()\n",
      "  driver.submit(job, options.submission_dir)\n",
      "filelist.txt:\n",
      "  /data/DAOD_PHYS.23295108._000430.pool.root.1\n",
      "  \n",
      "package_CMakeLists.txt:\n",
      "  # The name of the package:\n",
      "  atlas_subdir (analysis)\n",
      "  \n",
      "  # Add the shared library:\n",
      "  atlas_add_library (analysisLib\n",
      "    analysis/*.h Root/*.cxx\n",
      "    PUBLIC_HEADERS analysis\n",
      "    LINK_LIBRARIES AnaAlgorithmLib xAODTau )\n",
      "  \n",
      "  if (XAOD_STANDALONE)\n",
      "   # Add the dictionary (for AnalysisBase only):\n",
      "   atlas_add_dictionary (queryDict\n",
      "    analysis/query.h\n",
      "    analysis/selection.xml\n",
      "    LINK_LIBRARIES analysisLib)\n",
      "  endif ()\n",
      "  \n",
      "  if (NOT XAOD_STANDALONE)\n",
      "    # Add a component library for AthAnalysis only:\n",
      "    atlas_add_component (analysis\n",
      "      src/components/*.cxx\n",
      "      LINK_LIBRARIES analysisLib)\n",
      "  endif ()\n",
      "  \n",
      "  # Install files from the package:\n",
      "  atlas_install_joboptions( share/*_jobOptions.py )\n",
      "  atlas_install_scripts( share/*_eljob.py )\n",
      "query.cxx:\n",
      "  #include <AsgTools/MessageCheck.h>\n",
      "  #include <analysis/query.h>\n",
      "  #include \"xAODRootAccess/tools/TFileAccessTracer.h\"\n",
      "  \n",
      "  \n",
      "  #include \"xAODTau/DiTauJetContainer.h\"\n",
      "  \n",
      "  #include \"xAODTau/versions/DiTauJet_v1.h\"\n",
      "  \n",
      "  \n",
      "  #include <TTree.h>\n",
      "  \n",
      "  query :: query (const std::string& name,\n",
      "                                    ISvcLocator *pSvcLocator)\n",
      "      : EL::AnaAlgorithm (name, pSvcLocator)\n",
      "  {\n",
      "    // Here you put any code for the base initialization of variables,\n",
      "    // e.g. initialize all pointers to 0.  This is also where you\n",
      "    // declare all properties for your algorithm.  Note that things like\n",
      "    // resetting statistics variables or booking histograms should\n",
      "    // rather go into the initialize() function.\n",
      "  \n",
      "    // Turn off file access statistics reporting. This is, according to Attila, useful\n",
      "    // for GRID jobs, but not so much for other jobs. For those of us not located at CERN\n",
      "    // and for a large amount of data, this can sometimes take a minute.\n",
      "    // So we get rid of it.\n",
      "    xAOD::TFileAccessTracer::enableDataSubmission(false);\n",
      "  }\n",
      "  \n",
      "  StatusCode query :: initialize ()\n",
      "  {\n",
      "    // Here you do everything that needs to be done at the very\n",
      "    // beginning on each worker node, e.g. create histograms and output\n",
      "    // trees.  This method gets called before any input files are\n",
      "    // connected.\n",
      "  \n",
      "    \n",
      "    {\n",
      "    \n",
      "      ANA_CHECK (book (TTree (\"treeme\", \"My analysis ntuple\")));\n",
      "    \n",
      "      auto myTree = tree (\"treeme\");\n",
      "    \n",
      "      myTree->Branch(\"ditau_pt\", &_ditau_pt2);\n",
      "    \n",
      "    }\n",
      "    \n",
      "  \n",
      "    return StatusCode::SUCCESS;\n",
      "  }\n",
      "  \n",
      "  StatusCode query :: execute ()\n",
      "  {\n",
      "    // Here you do everything that needs to be done on every single\n",
      "    // events, e.g. read input variables, apply cuts, and fill\n",
      "    // histograms and trees.  This is where most of your actual analysis\n",
      "    // code will go.\n",
      "  \n",
      "    \n",
      "    {\n",
      "    \n",
      "      const DataVector<xAOD::DiTauJet_v1>* ditaujets0;\n",
      "    \n",
      "      {\n",
      "    \n",
      "        const DataVector<xAOD::DiTauJet_v1>* result = 0;\n",
      "    \n",
      "        ANA_CHECK (evtStore()->retrieve(result, \"DiTauJets_Tight_NOSYS\"));\n",
      "    \n",
      "        ditaujets0 = result;\n",
      "    \n",
      "      }\n",
      "    \n",
      "      for (auto &&i_obj1 : *ditaujets0)\n",
      "    \n",
      "      {\n",
      "    \n",
      "        _ditau_pt2 = (i_obj1->pt()/1000.0);\n",
      "    \n",
      "        tree(\"treeme\")->Fill();\n",
      "    \n",
      "      }\n",
      "    \n",
      "    }\n",
      "    \n",
      "  \n",
      "    return StatusCode::SUCCESS;\n",
      "  }\n",
      "  \n",
      "  \n",
      "  \n",
      "  StatusCode query :: finalize ()\n",
      "  {\n",
      "    // This method is the mirror image of initialize(), meaning it gets\n",
      "    // called after the last event has been processed on the worker node\n",
      "    // and allows you to finish up any objects you created in\n",
      "    // initialize() before they are written to disk.  This is actually\n",
      "    // fairly rare, since this happens separately for each worker node.\n",
      "    // Most of the time you want to do your post-processing on the\n",
      "    // submission node after all your histogram outputs have been\n",
      "    // merged.\n",
      "    return StatusCode::SUCCESS;\n",
      "  }\n",
      "query.h:\n",
      "  #ifndef analysis_query_H\n",
      "  #define analysis_query_H\n",
      "  \n",
      "  #include <AnaAlgorithm/AnaAlgorithm.h>\n",
      "  \n",
      "  class query : public EL::AnaAlgorithm\n",
      "  {\n",
      "  public:\n",
      "    // this is a standard algorithm constructor\n",
      "    query (const std::string& name, ISvcLocator* pSvcLocator);\n",
      "  \n",
      "    // these are the functions inherited from Algorithm\n",
      "    virtual StatusCode initialize () override;\n",
      "    virtual StatusCode execute () override;\n",
      "    virtual StatusCode finalize () override;\n",
      "  \n",
      "  private:\n",
      "    // Class level variables\n",
      "  \n",
      "    \n",
      "    double _ditau_pt2;\n",
      "  \n",
      "    \n",
      "  \n",
      "  };\n",
      "  \n",
      "  #endif\n",
      "runner.sh:\n",
      "  #!/bin/env bash\n",
      "  \n",
      "  # If any problem occurs during the running of this script we want to bail and make sure that\n",
      "  # everyone above us knows what happened.\n",
      "  set -e\n",
      "  \n",
      "  # Meant to be invokved in an ATLAS R21 analysis container.\n",
      "  # This follows the tutorial from https://atlassoftwaredocs.web.cern.ch/ABtutorial/release_setup/\n",
      "  \n",
      "  # Parse the command line arguments. Our defaults\n",
      "  output_method=\"cp\"\n",
      "  output_dir=\"/results\"\n",
      "  input_method=\"filelist\"\n",
      "  input_file=\"\"\n",
      "  compile=1\n",
      "  run=1\n",
      "  \n",
      "  while getopts \"d:o:cr\" opt; do\n",
      "      case \"$opt\" in\n",
      "      d)\n",
      "          input_method=\"cmd\"\n",
      "          input_file=$OPTARG\n",
      "          ;;\n",
      "      c)\n",
      "          run=0\n",
      "          ;;\n",
      "      r)\n",
      "          compile=0\n",
      "          ;;\n",
      "      o)\n",
      "          output_dir=$OPTARG\n",
      "          ;;\n",
      "      ?)\n",
      "          exit 10\n",
      "      esac\n",
      "  done\n",
      "  \n",
      "  # If there are any arguments left over, then very bad things have happened.\n",
      "  shift $((OPTIND-1))\n",
      "  if [ $# != 0 ]; then\n",
      "    echo \"Extra arguments on the command line $@\"\n",
      "    exit 1\n",
      "  fi\n",
      "  \n",
      "  # Setup and config\n",
      "  source /home/atlas/release_setup.sh\n",
      "  \n",
      "  # Remember where we are and the script location.\n",
      "  DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" >/dev/null 2>&1 && pwd )\"\n",
      "  local=`pwd`\n",
      "  \n",
      "  # Create a release directory\n",
      "  if [ $compile = 1 ]; then\n",
      "     mkdir rel\n",
      "     cd rel\n",
      "     mkdir source\n",
      "     mkdir build\n",
      "     mkdir run\n",
      "  \n",
      "  # Create cmake infrastructure\n",
      "     cat > source/CMakeLists.txt << 'EOF'\n",
      "  #\n",
      "  # Project configuration for UserAnalysis.\n",
      "  #\n",
      "  project(func_adl_ntupler)\n",
      "  \n",
      "  # Set the minimum required CMake version:\n",
      "  cmake_minimum_required( VERSION 3.4 FATAL_ERROR )\n",
      "  \n",
      "  # Try to figure out what project is our parent. Just using a hard-coded list\n",
      "  # of possible project names. Basically the names of all the other\n",
      "  # sub-directories inside the Projects/ directory in the repository.\n",
      "  set( _parentProjectNames Athena AthenaP1 AnalysisBase AthAnalysis\n",
      "     AthSimulation AthDerivation AnalysisTop )\n",
      "  set( _defaultParentProject AnalysisBase )\n",
      "  foreach( _pp ${_parentProjectNames} )\n",
      "     if( NOT \"$ENV{${_pp}_DIR}\" STREQUAL \"\" )\n",
      "        set( _defaultParentProject ${_pp} )\n",
      "        break()\n",
      "     endif()\n",
      "  endforeach()\n",
      "  \n",
      "  # Set the parent project name based on the previous findings:\n",
      "  set( ATLAS_PROJECT ${_defaultParentProject}\n",
      "     CACHE STRING \"The name of the parent project to build against\" )\n",
      "  \n",
      "  # Clean up:\n",
      "  unset( _parentProjectNames )\n",
      "  unset( _defaultParentProject )\n",
      "  \n",
      "  # Find the AnalysisBase project. This is what, amongst other things, pulls\n",
      "  # in the definition of all of the \"atlas_\" prefixed functions/macros.\n",
      "  find_package( ${ATLAS_PROJECT} REQUIRED )\n",
      "  \n",
      "  # Set up CTest. This makes sure that per-package build log files can be\n",
      "  # created if the user so chooses.\n",
      "  atlas_ctest_setup()\n",
      "  \n",
      "  # Set up the GitAnalysisTutorial project. With this CMake will look for \"packages\"\n",
      "  # in the current repository and all of its submodules, respecting the\n",
      "  # \"package_filters.txt\" file, and set up the build of those packages.\n",
      "  atlas_project( UserAnalysis 1.0.0\n",
      "     USE ${ATLAS_PROJECT} ${${ATLAS_PROJECT}_VERSION} )\n",
      "  \n",
      "  # Set up the runtime environment setup script. This makes sure that the\n",
      "  # project's \"setup.sh\" script can set up a fully functional runtime environment,\n",
      "  # including all the externals that the project uses.\n",
      "  lcg_generate_env( SH_FILE ${CMAKE_BINARY_DIR}/${ATLAS_PLATFORM}/env_setup.sh )\n",
      "  install( FILES ${CMAKE_BINARY_DIR}/${ATLAS_PLATFORM}/env_setup.sh\n",
      "     DESTINATION . )\n",
      "  \n",
      "  # Set up CPack. This call makes sure that an RPM or TGZ file can be created\n",
      "  # from the built project. Used by Panda to send the project to the grid worker\n",
      "  # nodes.\n",
      "  atlas_cpack_setup()\n",
      "  EOF\n",
      "  \n",
      "     # Create a package infrastructure\n",
      "     cd source\n",
      "     mkdir analysis\n",
      "     mkdir analysis/analysis\n",
      "     mkdir analysis/Root\n",
      "     mkdir analysis/src\n",
      "     mkdir analysis/src/components\n",
      "     mkdir analysis/share\n",
      "  \n",
      "     # Create the basics for cmake\n",
      "     cp $DIR/package_CMakeLists.txt analysis/CMakeLists.txt\n",
      "  \n",
      "     # Next, copy over the algorithm. The source directory needs to be correctly mounted.\n",
      "     cp $DIR/query.h analysis/analysis\n",
      "     cp $DIR/query.cxx analysis/Root\n",
      "     cp $DIR/ATestRun_eljob.py analysis/share\n",
      "     chmod +x analysis/share/ATestRun_eljob.py\n",
      "  \n",
      "     cat > analysis/analysis/queryDict.h << EOF\n",
      "  #ifndef analysis_query_DICT_H\n",
      "  #define analysis_query_DICT_H\n",
      "  \n",
      "  // This file includes all the header files that you need to create\n",
      "  // dictionaries for.\n",
      "  \n",
      "  #include <analysis/query.h>\n",
      "  \n",
      "  #endif\n",
      "  EOF\n",
      "  \n",
      "     cat > analysis/analysis/selection.xml << EOF\n",
      "  <lcgdict>\n",
      "  \n",
      "    <!-- This file contains a list of all classes for which a dictionary\n",
      "         should be created. -->\n",
      "  \n",
      "    <class name=\"query\" />\n",
      "     \n",
      "  </lcgdict>\n",
      "  EOF\n",
      "  \n",
      "  \n",
      "     # Do the build\n",
      "     cd ../build\n",
      "     cmake ../source\n",
      "     make\n",
      "  else\n",
      "     cd rel/build\n",
      "  fi\n",
      "  \n",
      "  # Sort out the input file location\n",
      "  if [ $run = 1 ]; then\n",
      "     source ${AnalysisBaseExternals_PLATFORM}/setup.sh\n",
      "     if [ \"$input_method\" == \"filelist\" ]; then\n",
      "        if [ -e $DIR/filelist.txt ]; then\n",
      "           cp $DIR/filelist.txt .\n",
      "        else\n",
      "           cp $local/filelist.txt .\n",
      "        fi\n",
      "     elif [ \"$input_method\" == \"cmd\" ]; then\n",
      "        echo $input_file > filelist.txt\n",
      "     fi\n",
      "  \n",
      "     # Do the run\n",
      "     if [ -e ./bogus ]; then\n",
      "       rm -rf bogus\n",
      "     fi\n",
      "     python ../source/analysis/share/ATestRun_eljob.py --submission-dir=bogus\n",
      "  \n",
      "     # Place the output file where it belongs\n",
      "     if [ $output_method == \"cp\" ]; then\n",
      "        cmd=\"cp\"\n",
      "        destination=$output_dir\n",
      "     else\n",
      "        destination=$1\n",
      "        cmd=\"cp\"\n",
      "        if [[ $destination == \"root:\"* ]]; then\n",
      "           cmd=\"xrdcp\"\n",
      "        fi\n",
      "     fi\n",
      "     $cmd ./bogus/data-ANALYSIS/ANALYSIS.root $destination\n",
      "  fi\n"
     ]
    },
    {
     "ename": "DockerException",
     "evalue": "The docker command executed was `C:\\Program Files\\Docker\\Docker\\resources\\bin\\docker.EXE container run --rm --volume C:\\Users\\gordo\\AppData\\Local\\Temp\\tmp2qhzzpei:/scripts:ro --volume C:\\Users\\gordo\\AppData\\Local\\Temp\\tmp2qhzzpei:/results: --volume C:\\Users\\gordo\\Code\\atlas\\data\\R21\\DAOD_PHYS\\361108:/data/:ro atlas/analysisbase:21.2.197 /scripts/runner.sh`.\nIt returned with code 1\nThe content of stdout can be found above the stacktrace (it wasn't captured).\nThe content of stderr is '[TFile::Cp] Total 4.45 MB\t|>...................| 0.00 % [0.0 MB/s]\r[TFile::Cp] Total 4.45 MB\t|====>...............| 21.43 % [3.0 MB/s]\r[TFile::Cp] Total 4.45 MB\t|========>...........| 42.86 % [2.8 MB/s]\r[TFile::Cp] Total 4.45 MB\t|============>.......| 64.28 % [2.8 MB/s]\r[TFile::Cp] Total 4.45 MB\t|=================>..| 85.71 % [2.8 MB/s]\r[TFile::Cp] Total 4.45 MB\t|====================| 100.00 % [2.8 MB/s]\r\n[TFile::Cp] Total 17.57 MB\t|>...................| 0.00 % [0.0 MB/s]\r[TFile::Cp] Total 17.57 MB\t|=>..................| 5.43 % [2.9 MB/s]\r[TFile::Cp] Total 17.57 MB\t|==>.................| 10.86 % [2.8 MB/s]\r[TFile::Cp] Total 17.57 MB\t|===>................| 16.28 % [2.8 MB/s]\r[TFile::Cp] Total 17.57 MB\t|====>...............| 21.71 % [2.7 MB/s]\r[TFile::Cp] Total 17.57 MB\t|=====>..............| 27.14 % [2.7 MB/s]\r[TFile::Cp] Total 17.57 MB\t|======>.............| 32.57 % [2.7 MB/s]\r[TFile::Cp] Total 17.57 MB\t|=======>............| 37.99 % [2.7 MB/s]\r[TFile::Cp] Total 17.57 MB\t|========>...........| 43.42 % [2.7 MB/s]\r[TFile::Cp] Total 17.57 MB\t|=========>..........| 48.85 % [2.7 MB/s]\r[TFile::Cp] Total 17.57 MB\t|==========>.........| 54.28 % [2.7 MB/s]\r[TFile::Cp] Total 17.57 MB\t|===========>........| 59.71 % [2.6 MB/s]\r[TFile::Cp] Total 17.57 MB\t|=============>......| 65.13 % [2.6 MB/s]\r[TFile::Cp] Total 17.57 MB\t|==============>.....| 70.56 % [2.6 MB/s]\r[TFile::Cp] Total 17.57 MB\t|===============>....| 75.99 % [2.6 MB/s]\r[TFile::Cp] Total 17.57 MB\t|================>...| 81.42 % [2.6 MB/s]\r[TFile::Cp] Total 17.57 MB\t|=================>..| 86.85 % [2.6 MB/s]\r[TFile::Cp] Total 17.57 MB\t|==================>.| 92.27 % [2.6 MB/s]\r[TFile::Cp] Total 17.57 MB\t|===================>| 97.70 % [2.6 MB/s]\r[TFile::Cp] Total 17.57 MB\t|====================| 100.00 % [2.5 MB/s]\r\n[TFile::Cp] Total 16.57 MB\t|>...................| 0.00 % [0.0 MB/s]\r[TFile::Cp] Total 16.57 MB\t|=>..................| 5.76 % [1.1 MB/s]\r[TFile::Cp] Total 16.57 MB\t|==>.................| 11.51 % [1.1 MB/s]\r[TFile::Cp] Total 16.57 MB\t|===>................| 17.27 % [1.4 MB/s]\r[TFile::Cp] Total 16.57 MB\t|====>...............| 23.03 % [1.6 MB/s]\r[TFile::Cp] Total 16.57 MB\t|=====>..............| 28.78 % [1.8 MB/s]\r[TFile::Cp] Total 16.57 MB\t|======>.............| 34.54 % [1.9 MB/s]\r[TFile::Cp] Total 16.57 MB\t|========>...........| 40.29 % [2.0 MB/s]\r[TFile::Cp] Total 16.57 MB\t|=========>..........| 46.05 % [2.0 MB/s]\r[TFile::Cp] Total 16.57 MB\t|==========>.........| 51.81 % [1.9 MB/s]\r[TFile::Cp] Total 16.57 MB\t|===========>........| 57.56 % [2.0 MB/s]\r[TFile::Cp] Total 16.57 MB\t|============>.......| 63.32 % [2.0 MB/s]\r[TFile::Cp] Total 16.57 MB\t|=============>......| 69.08 % [2.1 MB/s]\r[TFile::Cp] Total 16.57 MB\t|==============>.....| 74.83 % [2.1 MB/s]\r[TFile::Cp] Total 16.57 MB\t|================>...| 80.59 % [2.1 MB/s]\r[TFile::Cp] Total 16.57 MB\t|=================>..| 86.35 % [2.2 MB/s]\r[TFile::Cp] Total 16.57 MB\t|==================>.| 92.10 % [2.2 MB/s]\r[TFile::Cp] Total 16.57 MB\t|===================>| 97.86 % [2.1 MB/s]\r[TFile::Cp] Total 16.57 MB\t|====================| 100.00 % [2.1 MB/s]\r\n[TFile::Cp] Total 17.49 MB\t|>...................| 0.00 % [0.0 MB/s]\r[TFile::Cp] Total 17.49 MB\t|=>..................| 5.45 % [1.0 MB/s]\r[TFile::Cp] Total 17.49 MB\t|==>.................| 10.90 % [1.5 MB/s]\r[TFile::Cp] Total 17.49 MB\t|===>................| 16.35 % [1.7 MB/s]\r[TFile::Cp] Total 17.49 MB\t|====>...............| 21.81 % [1.6 MB/s]\r[TFile::Cp] Total 17.49 MB\t|=====>..............| 27.26 % [1.7 MB/s]\r[TFile::Cp] Total 17.49 MB\t|======>.............| 32.71 % [1.7 MB/s]\r[TFile::Cp] Total 17.49 MB\t|=======>............| 38.16 % [1.7 MB/s]\r[TFile::Cp] Total 17.49 MB\t|========>...........| 43.61 % [1.8 MB/s]\r[TFile::Cp] Total 17.49 MB\t|=========>..........| 49.06 % [1.9 MB/s]\r[TFile::Cp] Total 17.49 MB\t|==========>.........| 54.51 % [2.0 MB/s]\r[TFile::Cp] Total 17.49 MB\t|===========>........| 59.97 % [2.0 MB/s]\r[TFile::Cp] Total 17.49 MB\t|=============>......| 65.42 % [2.1 MB/s]\r[TFile::Cp] Total 17.49 MB\t|==============>.....| 70.87 % [2.1 MB/s]\r[TFile::Cp] Total 17.49 MB\t|===============>....| 76.32 % [2.1 MB/s]\r[TFile::Cp] Total 17.49 MB\t|================>...| 81.77 % [2.2 MB/s]\r[TFile::Cp] Total 17.49 MB\t|=================>..| 87.22 % [2.2 MB/s]\r[TFile::Cp] Total 17.49 MB\t|==================>.| 92.67 % [2.2 MB/s]\r[TFile::Cp] Total 17.49 MB\t|===================>| 98.13 % [2.2 MB/s]\r[TFile::Cp] Total 17.49 MB\t|====================| 100.00 % [2.2 MB/s]\r\nIn file included from libTauAnalysisAlgorithmsDict dictionary payload:48:\nIn file included from /usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/TauAnalysisAlgorithms/DiTauEfficiencyCorrectionsAlg.h:12:\nIn file included from /usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/TauAnalysisTools/IDiTauEfficiencyCorrectionsTool.h:23:\nIn file included from /usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/xAODTau/DiTauJet.h:12:\n/usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/xAODTau/versions/DiTauJet_v1.h:168:1: error: explicit specialization of 'DataVectorBase<xAOD::DiTauJet_v1>' after instantiation\nDATAVECTOR_BASE( xAOD::DiTauJet_v1, xAOD::IParticle );\n^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/AthContainers/DataVector.h:612:43: note: expanded from macro 'DATAVECTOR_BASE'\n#define DATAVECTOR_BASE(T, BASE)          \\\n                                          ^\n/usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/AthContainers/DataVector.h:622:20: note: expanded from macro '\\\nDATAVECTOR_BASE_FWD'\ntemplate <> struct DataVectorBase<T>      \\\n                   ^~~~~~~~~~~~~~~~~\n/usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/AthContainers/DataVector.h:718:42: note: implicit instantiation first required here\ntemplate <class T, class BASE = typename DataVectorBase<T>::Base>\n                                         ^\ninput_line_367:2:39: error: allocation of incomplete type 'CP::DiTauSmearingAlg'\n dynamic_cast<asg::AsgComponent*>(new CP::DiTauSmearingAlg (\"DiTauSmearingAlg_Tight\", nullptr))\n                                      ^~~~~~~~~~~~~~~~~~~~\nlibTauAnalysisAlgorithmsDict dictionary forward declarations' payload:6:106: note: forward declaration of 'CP::DiTauSmearingAlg'\nnamespace CP{class __attribute__((annotate(\"$clingAutoload$TauAnalysisAlgorithms/DiTauSmearingAlg.h\")))  DiTauSmearingAlg;}\n                                                                                                         ^\nTraceback (most recent call last):\n  File \"../source/analysis/share/ATestRun_eljob.py\", line 91, in <module>\n    driver.submit(job, options.submission_dir)\nException: string EL::Driver::submit(const EL::Job& job, const string& location) =>\n    failed to submit job (C++ exception of type runtime_error)\n'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDockerException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_198972/1011544379.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m taus = (ds\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0mSelectMany\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDiTauJets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DiTauJets\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0mSelect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m1000.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0mAsAwkwardArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ditau_pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         .value())\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\xaod-usage-w68Kx7k0-py3.9\\lib\\site-packages\\make_it_sync\\func_wrapper.py\u001b[0m in \u001b[0;36mwrapped_call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_sync_version_of_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\xaod-usage-w68Kx7k0-py3.9\\lib\\site-packages\\make_it_sync\\func_wrapper.py\u001b[0m in \u001b[0;36m_sync_version_of_function\u001b[1;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mfuture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_data_wrapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                 \u001b[1;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\thread.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\xaod-usage-w68Kx7k0-py3.9\\lib\\site-packages\\make_it_sync\\func_wrapper.py\u001b[0m in \u001b[0;36mget_data_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mexector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Event loop stopped before Future completed.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gordo\\code\\iris-hep\\func_adl\\func_adl\\object_stream.py\u001b[0m in \u001b[0;36mvalue_async\u001b[1;34m(self, executor, title)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;31m# Run it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mexe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_q_ast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_sync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_async\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gordo\\code\\iris-hep\\func_adl_servicex\\func_adl_servicex\\ServiceX.py\u001b[0m in \u001b[0;36mexecute_result_async\u001b[1;34m(self, a, title)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;31m# Run ghe query for real!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\xaod-usage-w68Kx7k0-py3.9\\lib\\site-packages\\servicex\\servicex_utils.py\u001b[0m in \u001b[0;36mcached_version_of_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{h} - processing request'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[0msx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_inmem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\xaod-usage-w68Kx7k0-py3.9\\lib\\site-packages\\servicex\\servicex.py\u001b[0m in \u001b[0;36mget_data_awkward_async\u001b[1;34m(self, selection_query, title)\u001b[0m\n\u001b[0;32m    334\u001b[0m     async def get_data_awkward_async(self, selection_query: str,\n\u001b[0;32m    335\u001b[0m                                      title: Optional[str] = None):\n\u001b[1;32m--> 336\u001b[1;33m         return self._converter.combine_awkward(await self._data_return(\n\u001b[0m\u001b[0;32m    337\u001b[0m             \u001b[0mselection_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_converter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_awkward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             title))\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\xaod-usage-w68Kx7k0-py3.9\\lib\\site-packages\\backoff\\_async.py\u001b[0m in \u001b[0;36mretry\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m                 \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mexception\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mgiveup_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mgiveup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\xaod-usage-w68Kx7k0-py3.9\\lib\\site-packages\\backoff\\_async.py\u001b[0m in \u001b[0;36mretry\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m                 \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mexception\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mgiveup_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mgiveup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\xaod-usage-w68Kx7k0-py3.9\\lib\\site-packages\\servicex\\servicex.py\u001b[0m in \u001b[0;36m_data_return\u001b[1;34m(self, selection_query, converter, title, data_format)\u001b[0m\n\u001b[0;32m    524\u001b[0m                                 \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         '''\n\u001b[1;32m--> 526\u001b[1;33m         all_data = {\n\u001b[0m\u001b[0;32m    527\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32masync\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream_return\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselection_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\xaod-usage-w68Kx7k0-py3.9\\lib\\site-packages\\servicex\\servicex.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    524\u001b[0m                                 \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         '''\n\u001b[1;32m--> 526\u001b[1;33m         all_data = {\n\u001b[0m\u001b[0;32m    527\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32masync\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream_return\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselection_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\xaod-usage-w68Kx7k0-py3.9\\lib\\site-packages\\servicex\\servicex.py\u001b[0m in \u001b[0;36m_stream_return\u001b[1;34m(self, selection_query, title, converter, data_format)\u001b[0m\n\u001b[0;32m    563\u001b[0m                    self._stream_local_files(selection_query, title, data_format))  # type: ignore\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 565\u001b[1;33m         \u001b[1;32masync\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mas_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    566\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\xaod-usage-w68Kx7k0-py3.9\\lib\\site-packages\\servicex\\servicex.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    559\u001b[0m                                 \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         '''\n\u001b[1;32m--> 561\u001b[1;33m         as_data = (StreamInfoData(f.file, await asyncio.ensure_future(converter(f.path)))\n\u001b[0m\u001b[0;32m    562\u001b[0m                    \u001b[1;32masync\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                    self._stream_local_files(selection_query, title, data_format))  # type: ignore\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\xaod-usage-w68Kx7k0-py3.9\\lib\\site-packages\\servicex\\servicex.py\u001b[0m in \u001b[0;36m_stream_local_files\u001b[1;34m(self, selection_query, title, data_format)\u001b[0m\n\u001b[0;32m    596\u001b[0m              self._get_files(selection_query, data_format, notifier, title))  # type: ignore\n\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m         \u001b[1;32masync\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mas_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mStreamInfoPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mawait\u001b[0m \u001b[0ma_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\xaod-usage-w68Kx7k0-py3.9\\lib\\site-packages\\servicex\\servicex.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[1;31m# Get all the files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[0mas_files\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             (f async for f in\n\u001b[0m\u001b[0;32m    596\u001b[0m              self._get_files(selection_query, data_format, notifier, title))  # type: ignore\n\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\xaod-usage-w68Kx7k0-py3.9\\lib\\site-packages\\servicex\\servicex.py\u001b[0m in \u001b[0;36m_get_files\u001b[1;34m(self, selection_query, data_type, notifier, title)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[1;31m# Get a request id - which might be cached, but if not, submit it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             \u001b[0mrequest_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_request_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;31m# Make sure cache status exists (user could have deleted, see #176)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\xaod-usage-w68Kx7k0-py3.9\\lib\\site-packages\\servicex\\servicex.py\u001b[0m in \u001b[0;36m_get_request_id\u001b[1;34m(self, client, query)\u001b[0m\n\u001b[0;32m    685\u001b[0m         \u001b[0mrequest_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookup_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrequest_id\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[0mrequest_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_servicex_adaptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m             \u001b[0mrequest_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequest_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'request_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gordo\\code\\iris-hep\\func_adl_servicex\\func_adl_servicex\\local_dataset.py\u001b[0m in \u001b[0;36msubmit_query\u001b[1;34m(self, _, json_query)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_query\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'selection'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_query\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'title'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjson_query\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         file_list = await self._ds.execute_result_async(\n\u001b[0m\u001b[0;32m     93\u001b[0m             \u001b[0mtext_ast_to_python_ast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mtitle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gordo\\code\\iris-hep\\func_adl_xaod\\func_adl_xAOD\\common\\local_dataset.py\u001b[0m in \u001b[0;36mexecute_result_async\u001b[1;34m(self, a, title)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mpython_on_whales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDockerException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dump_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_run_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain_script\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_docker_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[1;31m# Now that we have run, we can pluck out the result.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gordo\\code\\iris-hep\\func_adl_xaod\\func_adl_xAOD\\common\\local_dataset.py\u001b[0m in \u001b[0;36mexecute_result_async\u001b[1;34m(self, a, title)\u001b[0m\n\u001b[0;32m    129\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                 )\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mstream_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_content\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput_generator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mstream_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'stdout'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf'{stream_content.decode()}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\xaod-usage-w68Kx7k0-py3.9\\lib\\site-packages\\python_on_whales\\utils.py\u001b[0m in \u001b[0;36mstream_stdout_and_stderr\u001b[1;34m(full_cmd, env)\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[0mexit_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexit_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mDockerException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_cmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexit_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_stderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDockerException\u001b[0m: The docker command executed was `C:\\Program Files\\Docker\\Docker\\resources\\bin\\docker.EXE container run --rm --volume C:\\Users\\gordo\\AppData\\Local\\Temp\\tmp2qhzzpei:/scripts:ro --volume C:\\Users\\gordo\\AppData\\Local\\Temp\\tmp2qhzzpei:/results: --volume C:\\Users\\gordo\\Code\\atlas\\data\\R21\\DAOD_PHYS\\361108:/data/:ro atlas/analysisbase:21.2.197 /scripts/runner.sh`.\nIt returned with code 1\nThe content of stdout can be found above the stacktrace (it wasn't captured).\nThe content of stderr is '[TFile::Cp] Total 4.45 MB\t|>...................| 0.00 % [0.0 MB/s]\r[TFile::Cp] Total 4.45 MB\t|====>...............| 21.43 % [3.0 MB/s]\r[TFile::Cp] Total 4.45 MB\t|========>...........| 42.86 % [2.8 MB/s]\r[TFile::Cp] Total 4.45 MB\t|============>.......| 64.28 % [2.8 MB/s]\r[TFile::Cp] Total 4.45 MB\t|=================>..| 85.71 % [2.8 MB/s]\r[TFile::Cp] Total 4.45 MB\t|====================| 100.00 % [2.8 MB/s]\r\n[TFile::Cp] Total 17.57 MB\t|>...................| 0.00 % [0.0 MB/s]\r[TFile::Cp] Total 17.57 MB\t|=>..................| 5.43 % [2.9 MB/s]\r[TFile::Cp] Total 17.57 MB\t|==>.................| 10.86 % [2.8 MB/s]\r[TFile::Cp] Total 17.57 MB\t|===>................| 16.28 % [2.8 MB/s]\r[TFile::Cp] Total 17.57 MB\t|====>...............| 21.71 % [2.7 MB/s]\r[TFile::Cp] Total 17.57 MB\t|=====>..............| 27.14 % [2.7 MB/s]\r[TFile::Cp] Total 17.57 MB\t|======>.............| 32.57 % [2.7 MB/s]\r[TFile::Cp] Total 17.57 MB\t|=======>............| 37.99 % [2.7 MB/s]\r[TFile::Cp] Total 17.57 MB\t|========>...........| 43.42 % [2.7 MB/s]\r[TFile::Cp] Total 17.57 MB\t|=========>..........| 48.85 % [2.7 MB/s]\r[TFile::Cp] Total 17.57 MB\t|==========>.........| 54.28 % [2.7 MB/s]\r[TFile::Cp] Total 17.57 MB\t|===========>........| 59.71 % [2.6 MB/s]\r[TFile::Cp] Total 17.57 MB\t|=============>......| 65.13 % [2.6 MB/s]\r[TFile::Cp] Total 17.57 MB\t|==============>.....| 70.56 % [2.6 MB/s]\r[TFile::Cp] Total 17.57 MB\t|===============>....| 75.99 % [2.6 MB/s]\r[TFile::Cp] Total 17.57 MB\t|================>...| 81.42 % [2.6 MB/s]\r[TFile::Cp] Total 17.57 MB\t|=================>..| 86.85 % [2.6 MB/s]\r[TFile::Cp] Total 17.57 MB\t|==================>.| 92.27 % [2.6 MB/s]\r[TFile::Cp] Total 17.57 MB\t|===================>| 97.70 % [2.6 MB/s]\r[TFile::Cp] Total 17.57 MB\t|====================| 100.00 % [2.5 MB/s]\r\n[TFile::Cp] Total 16.57 MB\t|>...................| 0.00 % [0.0 MB/s]\r[TFile::Cp] Total 16.57 MB\t|=>..................| 5.76 % [1.1 MB/s]\r[TFile::Cp] Total 16.57 MB\t|==>.................| 11.51 % [1.1 MB/s]\r[TFile::Cp] Total 16.57 MB\t|===>................| 17.27 % [1.4 MB/s]\r[TFile::Cp] Total 16.57 MB\t|====>...............| 23.03 % [1.6 MB/s]\r[TFile::Cp] Total 16.57 MB\t|=====>..............| 28.78 % [1.8 MB/s]\r[TFile::Cp] Total 16.57 MB\t|======>.............| 34.54 % [1.9 MB/s]\r[TFile::Cp] Total 16.57 MB\t|========>...........| 40.29 % [2.0 MB/s]\r[TFile::Cp] Total 16.57 MB\t|=========>..........| 46.05 % [2.0 MB/s]\r[TFile::Cp] Total 16.57 MB\t|==========>.........| 51.81 % [1.9 MB/s]\r[TFile::Cp] Total 16.57 MB\t|===========>........| 57.56 % [2.0 MB/s]\r[TFile::Cp] Total 16.57 MB\t|============>.......| 63.32 % [2.0 MB/s]\r[TFile::Cp] Total 16.57 MB\t|=============>......| 69.08 % [2.1 MB/s]\r[TFile::Cp] Total 16.57 MB\t|==============>.....| 74.83 % [2.1 MB/s]\r[TFile::Cp] Total 16.57 MB\t|================>...| 80.59 % [2.1 MB/s]\r[TFile::Cp] Total 16.57 MB\t|=================>..| 86.35 % [2.2 MB/s]\r[TFile::Cp] Total 16.57 MB\t|==================>.| 92.10 % [2.2 MB/s]\r[TFile::Cp] Total 16.57 MB\t|===================>| 97.86 % [2.1 MB/s]\r[TFile::Cp] Total 16.57 MB\t|====================| 100.00 % [2.1 MB/s]\r\n[TFile::Cp] Total 17.49 MB\t|>...................| 0.00 % [0.0 MB/s]\r[TFile::Cp] Total 17.49 MB\t|=>..................| 5.45 % [1.0 MB/s]\r[TFile::Cp] Total 17.49 MB\t|==>.................| 10.90 % [1.5 MB/s]\r[TFile::Cp] Total 17.49 MB\t|===>................| 16.35 % [1.7 MB/s]\r[TFile::Cp] Total 17.49 MB\t|====>...............| 21.81 % [1.6 MB/s]\r[TFile::Cp] Total 17.49 MB\t|=====>..............| 27.26 % [1.7 MB/s]\r[TFile::Cp] Total 17.49 MB\t|======>.............| 32.71 % [1.7 MB/s]\r[TFile::Cp] Total 17.49 MB\t|=======>............| 38.16 % [1.7 MB/s]\r[TFile::Cp] Total 17.49 MB\t|========>...........| 43.61 % [1.8 MB/s]\r[TFile::Cp] Total 17.49 MB\t|=========>..........| 49.06 % [1.9 MB/s]\r[TFile::Cp] Total 17.49 MB\t|==========>.........| 54.51 % [2.0 MB/s]\r[TFile::Cp] Total 17.49 MB\t|===========>........| 59.97 % [2.0 MB/s]\r[TFile::Cp] Total 17.49 MB\t|=============>......| 65.42 % [2.1 MB/s]\r[TFile::Cp] Total 17.49 MB\t|==============>.....| 70.87 % [2.1 MB/s]\r[TFile::Cp] Total 17.49 MB\t|===============>....| 76.32 % [2.1 MB/s]\r[TFile::Cp] Total 17.49 MB\t|================>...| 81.77 % [2.2 MB/s]\r[TFile::Cp] Total 17.49 MB\t|=================>..| 87.22 % [2.2 MB/s]\r[TFile::Cp] Total 17.49 MB\t|==================>.| 92.67 % [2.2 MB/s]\r[TFile::Cp] Total 17.49 MB\t|===================>| 98.13 % [2.2 MB/s]\r[TFile::Cp] Total 17.49 MB\t|====================| 100.00 % [2.2 MB/s]\r\nIn file included from libTauAnalysisAlgorithmsDict dictionary payload:48:\nIn file included from /usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/TauAnalysisAlgorithms/DiTauEfficiencyCorrectionsAlg.h:12:\nIn file included from /usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/TauAnalysisTools/IDiTauEfficiencyCorrectionsTool.h:23:\nIn file included from /usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/xAODTau/DiTauJet.h:12:\n/usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/xAODTau/versions/DiTauJet_v1.h:168:1: error: explicit specialization of 'DataVectorBase<xAOD::DiTauJet_v1>' after instantiation\nDATAVECTOR_BASE( xAOD::DiTauJet_v1, xAOD::IParticle );\n^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/AthContainers/DataVector.h:612:43: note: expanded from macro 'DATAVECTOR_BASE'\n#define DATAVECTOR_BASE(T, BASE)          \\\n                                          ^\n/usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/AthContainers/DataVector.h:622:20: note: expanded from macro '\\\nDATAVECTOR_BASE_FWD'\ntemplate <> struct DataVectorBase<T>      \\\n                   ^~~~~~~~~~~~~~~~~\n/usr/AnalysisBase/21.2.197/InstallArea/x86_64-centos7-gcc8-opt/include/AthContainers/DataVector.h:718:42: note: implicit instantiation first required here\ntemplate <class T, class BASE = typename DataVectorBase<T>::Base>\n                                         ^\ninput_line_367:2:39: error: allocation of incomplete type 'CP::DiTauSmearingAlg'\n dynamic_cast<asg::AsgComponent*>(new CP::DiTauSmearingAlg (\"DiTauSmearingAlg_Tight\", nullptr))\n                                      ^~~~~~~~~~~~~~~~~~~~\nlibTauAnalysisAlgorithmsDict dictionary forward declarations' payload:6:106: note: forward declaration of 'CP::DiTauSmearingAlg'\nnamespace CP{class __attribute__((annotate(\"$clingAutoload$TauAnalysisAlgorithms/DiTauSmearingAlg.h\")))  DiTauSmearingAlg;}\n                                                                                                         ^\nTraceback (most recent call last):\n  File \"../source/analysis/share/ATestRun_eljob.py\", line 91, in <module>\n    driver.submit(job, options.submission_dir)\nException: string EL::Driver::submit(const EL::Job& job, const string& location) =>\n    failed to submit job (C++ exception of type runtime_error)\n'\n"
     ]
    }
   ],
   "source": [
    "taus = (ds\n",
    "        .SelectMany(lambda e: e.DiTauJets(\"DiTauJets\"))\n",
    "        .Select(lambda t: t.pt() / 1000.0)\n",
    "        .AsAwkwardArray('ditau_pt')\n",
    "        .value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(taus.ditau_pt, bins=100, range=(0, 500))\n",
    "plt.xlabel('Tau $p_T$ [GeV]')\n",
    "plt.ylabel('Number of Taus')\n",
    "_ = plt.title('Tau $p_T$ distribution for $Z\\\\rightarrow \\\\tau \\\\tau$ events')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration\n",
    "\n",
    "By default the taus we pulled from above are calibrated, and the best central value for the tau collection you request is returned. This section shows you how to:\n",
    "\n",
    "* Pull out the raw, uncalibrated taus\n",
    "* How to get a particular systematic variation\n",
    "\n",
    "Because we want to do a comparison, and the tau corrections change the number of tau jets, we will need to do tau matching in $\\eta-\\phi$ space. Lets get the default calibration with eta and phi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ditaus = (ds\n",
    "          .Select(lambda e: e.DiTauJets(\"DiTauJets\"))\n",
    "          .Select(lambda taus: {\n",
    "              'pt': taus.Select(lambda t: t.pt() / 1000.0),\n",
    "              'eta': taus.Select(lambda t: t.eta()),\n",
    "              'phi': taus.Select(lambda t: t.phi()),\n",
    "          })\n",
    "          .AsAwkwardArray()\n",
    "          .value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To grab the raw jets (without calibration) we just set the `calibrated` parameter to `None` (there is very little reason one will do this normally):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ditaus = (ds\n",
    "              .Select(lambda e: e.DiTauJets(\"DiTauJets\", calibration=None))\n",
    "              .Select(lambda taus: {\n",
    "                  'pt': taus.Select(lambda t: t.pt() / 1000.0),\n",
    "                  'eta': taus.Select(lambda t: t.eta()),\n",
    "                  'phi': taus.Select(lambda t: t.phi()),\n",
    "              })\n",
    "              .AsAwkwardArray()\n",
    "              .value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of taus and the number of calibrated taus are quite different, so we'll need to match them in $\\eta$ and $\\phi$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_taus_matched = match_objects(taus, raw_taus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ak.flatten(taus.pt-raw_taus_matched.pt)/1000.0, bins=100, range=(-0.1, 0.1))\n",
    "plt.xlabel('$\\Delta p_T$ for calibrated taus matched to their raw taus [GeV]')\n",
    "plt.ylabel('Number of Taus')\n",
    "_ = plt.title('The effect of tau calibration on tau $p_T$ in $Z\\\\rightarrow \\\\tau\\\\tau$ events')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we instead want a particular systematic error, we need only name that error to get it back. Knowing what the names of the systematic errors, however, is not something that can be programmatically determined ahead of time. See the further information section at the end of this chapter to links to the ATLAS jet calibration info twiki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_taus = (ds\n",
    "           .Select(lambda e: e.TauJets(\"TauJets\", calibration=\"TAUS_TRUEHADTAU_SME_TES_DETECTOR__1up\"))\n",
    "           .Select(lambda taus: {\n",
    "               'pt': taus.Select(lambda t: t.pt() / 1000.0),\n",
    "               'eta': taus.Select(lambda t: t.eta()),\n",
    "               'phi': taus.Select(lambda t: t.phi()),\n",
    "            })\n",
    "           .AsAwkwardArray()\n",
    "           .value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_taus_matched = match_objects(taus, sys_taus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ak.flatten(taus.pt-sys_taus_matched.pt)/1000.0, bins=100, range=(-0.05, 0.05))\n",
    "plt.xlabel('$\\Delta p_T$ for calibrated taus matched to their $\\phi-\\eta$ raw taus [GeV]')\n",
    "plt.ylabel('Number of Taus')\n",
    "plt.yscale('log')\n",
    "_ = plt.title('The effect of a tau calibration sys error on tau $p_T$ in $Z\\\\rightarrow \\\\tau\\\\tau$ events')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Datamodel\n",
    "\n",
    "The data model when this documentation was last built was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func_adl_servicex_xaodr21.xAOD.ditaujet_v1 import DiTauJet_v1\n",
    "help(DiTauJet_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Information\n",
    "\n",
    "* The [`xAOD::TauJet_v3` C++ header file](https://gitlab.cern.ch/atlas/athena/-/blob/21.2/Event/xAOD/xAODTau/xAODTau/versions/TauJet_v3.h) with all the inline documentation.\n",
    "* The [Tau Recommendation Pages for R21](https://twiki.cern.ch/twiki/bin/view/AtlasProtected/TauRecommendationsR21) on the ATLAS TWiki"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4373964a7db18cf126f92f2b701a24b82fcc263e81b1ec161a400db7f7fa2af5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit (system)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
